{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c6bf6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "MathJax.Hub.Config({\n",
       "    TeX: { equationNumbers: { autoNumber: \"AMS\" } }\n",
       "});\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "MathJax.Hub.Config({\n",
    "    TeX: { equationNumbers: { autoNumber: \"AMS\" } }\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5303c84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import invwishart\n",
    "\n",
    "from tensorflow_probability.substrates import numpy as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7147d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSERIRE I DATI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196fc9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef0b4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_one_gibbs(data, cluster_allocs, uniq_vals, weights):\n",
    "    \"\"\"\n",
    "    Runs one iteration of the gibbs sampler\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: a numpy array of floats, contains the observations\n",
    "    cluster_allocs: a numpy array of integers, contains the c_i's(same length of data)\n",
    "    uniq_vals: a numpy array of size [K, 2], contains (mean, variance) for every component\n",
    "    weights: a numpy array of size [K], contains the weights of the components\n",
    "    \"\"\"\n",
    "    \n",
    "    n_clus = len(weights)\n",
    "    \n",
    "    for h in range(n_clus):\n",
    "        clusdata = data[cluster_allocs == h]\n",
    "        if len(clusdata) == 0:\n",
    "            uniq_vals[h, :] = sample_uniq_vals_prior()\n",
    "        else:\n",
    "            uniq_vals[h, :] = sample_uniq_vals_fullcond(clusdata)\n",
    "    \n",
    "    cluster_allocs = update_cluster_allocs(data, weights, uniq_vals)\n",
    "    \n",
    "    weights = update_weights(cluster_allocs, n_clus)\n",
    "    \n",
    "    return cluster_allocs, uniq_vals, weights\n",
    "\n",
    "\n",
    "\n",
    "def run_mcmc(data, k, niter=7500, nburn=2500, thin=5):\n",
    "    cluster_allocs = tfd.Categorical(probs=np.ones(k) / k).sample(len(data))\n",
    "    weights = np.ones(k) / k\n",
    "    \n",
    "    ### CAPIRE LA INVERSE WISHART\n",
    "    uniq_vals = np.dstack([\n",
    "        tfd.MultivariateNormalFullCovariance(np.mean(np.array(data)), np.diag(20*np.ones(k))).sample(k),\n",
    "        invwishart.rvs(df = k+1, scale = np.diag(2*np.ones(k)),size=k)\n",
    "    \n",
    "    allocs_out = []\n",
    "    uniq_vals_out = []\n",
    "    weights_out = []\n",
    "    \n",
    "    for i in range(niter):\n",
    "        cluster_allocs, uniq_vals, weights = run_one_gibbs(\n",
    "            data, cluster_allocs, uniq_vals, weights)\n",
    "        \n",
    "        if i > nburn and i % thin == 0:\n",
    "            allocs_out.append(cluster_allocs)\n",
    "            uniq_vals_out.append(uniq_vals)\n",
    "            weights_out.append(weights)\n",
    "            \n",
    "        if i % 10 == 0:\n",
    "            print(\"\\rIter {0} / {1}\".format(i+1, niter), flush=True, end=\" \")\n",
    "            \n",
    "    return allocs_out, uniq_vals_out, weights_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705b2855",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_probability.substrates import numpy as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "\n",
    "def update_cluster_allocs(data, weights, uniq_vals):\n",
    "    \n",
    "    logprobs = tfd.Normal(\n",
    "        uniq_vals[:, 0], np.sqrt(uniq_vals[:, 1])).log_prob(data[:, np.newaxis])\n",
    "    logprobs += np.log(weights)\n",
    "    probs =  np.exp(logprobs)/np.sum(np.exp(logprobs))\n",
    "    return tfd.Categorical(probs=probs).sample()\n",
    "\n",
    "\n",
    "def update_weights(cluster_allocs, n_clus, k):\n",
    "\n",
    "    n_by_clus = np.array([np.sum(cluster_allocs == h) for h in range(n_clus)])\n",
    "    post_params = np.ones(k) / k + n_by_clus\n",
    "    return tfd.Dirichlet(post_params.astype(float)).sample()\n",
    "\n",
    "\n",
    "def sample_uniq_vals_prior():\n",
    "    \n",
    "    var = invwishart.rvs(df = k+1, scale = np.diag(2*np.ones(k)),size=k)\n",
    "    mu = tfd.MultivariateNormalFullCovariance(np.mean(np.array(data)), np.diag(20*np.ones(k))).sample(k)\n",
    "    return np.array([mu, var])\n",
    "    \n",
    "\n",
    "def sample_uniq_vals_fullcond(clusdata):\n",
    "    \n",
    "    n=len(clusdata)\n",
    "    \n",
    "    var = invwishart.rvs(df = k+1+n, scale = np.diag(2*np.ones(k))+np.cov(clusdata)+(n/1+n)*np.dot(np.mean(clusdata)-np.mean(data),np.mean(clusdata)-np.mean(data))\n",
    "                         ,size=k)\n",
    "    mu = tfd.MultivariateNormalFullCovariance((np.mean(np.array(data))+n*np.mean(clusdata))/(1+n), np.diag(20*np.ones(k))/(1+n)).sample(k)\n",
    "    return np.array([mu, var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff680c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "allocs_out, uniq_vals_out, weights_out = run_mcmc(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1181a79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data, density=True, alpha=0.1)\n",
    "for h in range(k):\n",
    "    currd = data[allocs_out[-1] == h]\n",
    "    plt.scatter(currd, np.zeros_like(currd) + 0.001 * (h+1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
